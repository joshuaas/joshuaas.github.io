<div class="card mt-3 p-3">
  <div>
    <ul class="card-text font-weight-light list-group list-group-flush">
      <li class="list-group-item">
        <div class="row">
          <!-- <div class="col-xs-2 cl-sm-2 col-md-2 text-center" style="width: 75px;">
            <span class="badge font-weight-bold danger-color-dark text-uppercase align-middle" style="min-width: 75px;">
              Xcurve
            </span>
          </div> -->
          
          <div class="col-xs-12 cl-sm-12 col-md-12 mt-2 mt-md-0">
            <div style="padding-left:15px;">
              <a class="title font-weight-bold" style="color: #7da0b6;">
                Decision Invariant Optimization (Xcurve Framework)
              </a>
            </div>
  
            <!-- <div style="margin-top:20px;margin-bottom:20px;padding-left:15px;"><img src="{{ content.pic }}" class="col-md-10" style="padding-left:0px;"/></div> -->
            
            
            <p class="col-md-12" style="text-align:justify; margin-top: 20px;">
              Recently, machine learning and deep learning technologies have been successfully employed in many complicated high-stake decision-making applications such as disease prediction, fraud detection, outlier detection, and criminal justice sentencing. All these applications share a common trait known as risk-aversion in economics and finance terminologies. In other words, the decision-makers tend to have an extremely low risk tolerance. Under this context, the decision-makers will carefully choose their decision parameter to meet the specific requirement. Consequently, the decision parameters for train- and test- might be quite different. To mitigate the decision parameter shift problem,  I'm seeking for new decision-invariant machine learning machanisms , on top of which we develop a new framework called <a href="https://xcurveopt.github.io/">Xcurve</a>
            </p>
            
            <p class="col-md-12" style="text-align:justify;">
              The goal of X-curve learning is to learn high-quality models that can adapt to different decision conditions. Inspired by the fundamental principle of the well-known AUC optimization, our library provides a systematic solution to optimize the area under different kinds of performance curves. To be more specific, the performance curve is formed by a plot of two performance functions $x(\lambda)$, $y(\lambda)$ of decision parameter $\lambda$. The area under a performance curve becomes the integral of the performance over all possible choices of different decision conditions. In this way, the learning systems are only required to optimize a decision-invariant metric to avoid the risk aversion issue
            </p> 
            
            <div style="margin-top:20px; margin-bottom:20px; display: flex; justify-content: center;"><img src="/assets/img/xcurve.png" class="col-md-12"/></div>

            <p class="col-md-12" style="text-align: center; margin-top: 10px;">
              Four Kinds of Performance Curves
            </p>

            <div style="margin-top:20px; margin-bottom:20px; display: flex; justify-content: center;"><img src="/assets/img/xcurve-insight.png" class="col-md-12"/></div>            
            
            <ul class="items col-md-12">
              <li>
                <span class="item-title">AUROC</span>
                <ul class="subitems">
                  <li>
                    <span class="subitem">Partial performance constraints(only focus on subset of TPR, FPR)</span>
                    
                    {% include research_papers.html paper_titles=page.paper_titles_partial %}

                  </li>
                </ul>

                <ul class="subitems">
                  <li>
                    <span class="subitem">Multiclass extension</span>  
                    
                    {% include research_papers.html paper_titles=page.paper_titles_multiclass %}
                  </li>
                </ul>

                <ul class="subitems">
                  <li>
                    <span class="subitem">Generalized AUC with non-uniform cost/threshold distribution</span>  
                    
                    {% include research_papers.html paper_titles=page.paper_titles_generalized %}
                  </li>
                </ul>

              </li>
            </ul>
            
          </div>
        </div>
      </li>

      <li class="list-group-item">
        <div class="row">
          <!-- <div class="col-xs-2 cl-sm-2 col-md-2 text-center" style="width: 75px;">
            <span class="badge font-weight-bold danger-color-dark text-uppercase align-middle" style="min-width: 75px;">
              Xcurve
            </span>
          </div> -->
          
          <div class="col-xs-12 cl-sm-12 col-md-12 mt-2 mt-md-0">
            <div style="padding-left:15px;">
              <a class="title font-weight-bold" style="color: #7da0b6;">
                Trustworthy Machine Learning 
              </a>
            </div>
  
            <!-- <div style="margin-top:20px;margin-bottom:20px;padding-left:15px;"><img src="{{ content.pic }}" class="col-md-10" style="padding-left:0px;"/></div> -->
            
            
            <p class="col-md-12" style="text-align:justify; margin-top: 20px;">
              We are seeking for new principled method to make the current machine learning system trustworthy (e.g. Robustness against Adversarial attacks, OOD examples). On top of Xcurve, I'm especially interested in  (a) how to design performance-based metrics for trustworthy machine learning, and (b) how to use the SOTA models and idea of trustworthy machine learning to improve the Xcurve Framework. 
            </p>
            
            <!-- <div style="margin-top:20px;margin-bottom:20px;display: flex; justify-content: center;"><img src="/assets/img/xcurve.png" class="col-md-12"/></div> -->
            
          </div>
        </div>
      </li>

      <li class="list-group-item">
        <div class="row">
          <!-- <div class="col-xs-2 cl-sm-2 col-md-2 text-center" style="width: 75px;">
            <span class="badge font-weight-bold danger-color-dark text-uppercase align-middle" style="min-width: 75px;">
              Xcurve
            </span>
          </div> -->
          
          <div class="col-xs-12 cl-sm-12 col-md-12 mt-2 mt-md-0">
            <div style="padding-left:15px;">
              <a class="title font-weight-bold" style="color: #7da0b6;">
                Long-tail Learning
              </a>
            </div>
  
            <!-- <div style="margin-top:20px;margin-bottom:20px;padding-left:15px;"><img src="{{ content.pic }}" class="col-md-10" style="padding-left:0px;"/></div> -->
            
            
            <p class="col-md-12" style="text-align:justify; margin-top: 20px;">
              Long-tail learning is one of the most challenging problems in machine learning, which aims to train well-performing models from a large number of examples that follow a highly imbalanced class distribution. We find that the long-tail problem could be mitigated by adjusting the optimal decision rule. On top of the Xcurve framework, we are interested in (a) how to design distribution-invariant metrics for long-tail learning to deal with different long-tail distributions, and (b) how to directly optimize such metrics efficiently. 
            </p>
            
            <!-- <div style="margin-top:20px;margin-bottom:20px;display: flex; justify-content: center;"><img src="/assets/img/xcurve.png" class="col-md-12"/></div> -->
            
          </div>
        </div>
      </li>

    </ul>
  </div>
</div>
  
